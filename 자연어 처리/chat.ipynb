{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31958,"status":"ok","timestamp":1694405445743,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"6rHXw-Vy0VJg","outputId":"92ca55c9-54bf-4e1a-9c12-5b5657862ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"08e5jaKI0aTE"},"outputs":[],"source":["import tensorflow as tf\n","from transformers import AutoTokenizer\n","from transformers import TFGPT2LMHeadModel\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5599,"status":"ok","timestamp":1694406002900,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"hYs0-dt10dn7","outputId":"a329903c-bdbd-4b3b-8b28-33d141f418f5"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}],"source":["# 허깅페이스 transformers 에 등록된 사전 학습된 koGTP2 토크나이저를 가져온다.\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","  bos_token = '</s>', eos_token = '</s>', unk_token = '<unk>',\n","  pad_token = '<pad>', mask_token = '<mask>')\n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","\n","# tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='', eos_token='', pad_token='')\n","# model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694406002900,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"E5PM_q9Q0hHS","outputId":"342292b8-a632-47d3-c4de-89dde7689ef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","1\n","3\n","----------\n","</s>\n","<usr>\n","<pad>\n","<sys>\n"]}],"source":["print(tokenizer.bos_token_id)\n","print(tokenizer.eos_token_id)\n","print(tokenizer.pad_token_id)\n","print('-' * 10)\n","print(tokenizer.decode(1))\n","print(tokenizer.decode(2))\n","print(tokenizer.decode(3))\n","print(tokenizer.decode(4))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6tMXoMxx04sj"},"outputs":[],"source":["import pandas as pd\n","import tqdm\n","import urllib.request"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1694406005290,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"BeQ-Qnzh06xC","outputId":"385ea27b-6db3-4559-b6f1-f2cbd8ac1856"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-87156bea-b867-4982-a032-3924c647dc7e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87156bea-b867-4982-a032-3924c647dc7e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-87156bea-b867-4982-a032-3924c647dc7e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-87156bea-b867-4982-a032-3924c647dc7e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-88f2b2c3-f562-4584-a74b-7b047e3da76b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88f2b2c3-f562-4584-a74b-7b047e3da76b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-88f2b2c3-f562-4584-a74b-7b047e3da76b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                 Q            A  label\n","0           12시 땡!   하루가 또 가네요.      0\n","1      1지망 학교 떨어졌어    위로해 드립니다.      0\n","2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n","3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n","4          PPL 심하네   눈살이 찌푸려지죠.      0"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","                           filename = \"ChatBotData.csv\")\n","train_data = pd.read_csv('ChatBotData.csv')\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1694406005715,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"YFQVBaEH09lD","outputId":"86bc11c0-4a8e-4bd4-a1fb-f3cf3848dcfa"},"outputs":[{"data":{"text/plain":["11823"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yoh7kSJr1D0b"},"outputs":[],"source":["def get_chat_data():\n","  for questions, answers in zip(train_data.Q.to_list(), train_data.A.to_list()):\n","    bos_token = [tokenizer.bos_token_id]\n","    eos_token = [tokenizer.eos_token_id]\n","    sent = tokenizer.encode('' + questions + '' + answers)\n","    yield bos_token + sent + eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EoZLdqmL1Hw0"},"outputs":[],"source":["dataset = tf.data.Dataset.from_generator(get_chat_data, output_types = tf.int32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"elapsed":301,"status":"error","timestamp":1694406051219,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"P6tizT8f1J87","outputId":"0bb9f700-4826-4bec-cac3-4ea606c5a475"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-33ae547c9326>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[0;34m(self, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m   2003\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpadded_batch_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m     return padded_batch_op._padded_batch(self, batch_size, padded_shapes,\n\u001b[0m\u001b[1;32m   2006\u001b[0m                                          padding_values, drop_remainder, name)\n\u001b[1;32m   2007\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m_padded_batch\u001b[0;34m(input_dataset, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise ValueError(f\"You must provide `padded_shapes` argument because \"\n\u001b[1;32m     45\u001b[0m                          f\"component {i} has unknown rank.\")\n\u001b[0;32m---> 46\u001b[0;31m   return _PaddedBatchDataset(\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m    214\u001b[0m         nest.flatten(input_shapes), flat_padded_shapes):\n\u001b[1;32m    215\u001b[0m       flat_padded_shapes_as_tensors.append(\n\u001b[0;32m--> 216\u001b[0;31m           _padded_shape_to_tensor(padded_shape, input_component_shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     self._padded_shapes = nest.pack_sequence_as(input_shapes,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m_padded_shape_to_tensor\u001b[0;34m(padded_shape, input_component_shape)\u001b[0m\n\u001b[1;32m    121\u001b[0m   if not _is_padded_shape_compatible_with(padded_shape_as_shape,\n\u001b[1;32m    122\u001b[0m                                           input_component_shape):\n\u001b[0;32m--> 123\u001b[0;31m     raise ValueError(f\"The padded shape {padded_shape_as_shape} is not \"\n\u001b[0m\u001b[1;32m    124\u001b[0m                      \u001b[0;34mf\"compatible with the shape {input_component_shape} of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                      f\"the corresponding input component.\")\n","\u001b[0;31mValueError\u001b[0m: The padded shape (None,) is not compatible with the shape (None, None) of the corresponding input component."]}],"source":["batch_size = 32\n","dataset = dataset.padded_batch(batch_size = batch_size, padded_shapes=(None,), padding_values=tokenizer.pad_token_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1694406008021,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"CU9vMSNj1QWL","outputId":"175c0d47-85ae-4a2d-f9dd-6ec4c415cee7"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[    1  9349  7888   739  7318   376 25000  6824  9108  9028  7098 25856\n","      1     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9020  8263  7497 10192 11615  8210  8006 11567  8711  9535  7483\n","  12521     1     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9085  7597   395  8149 10624  7397 24224 13358  7182  8030 19138\n","  16899  9677  8234   389     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9085  7597   395  8149  9465 10624  7397 24224 13358  7182  8030\n","  19138 16899  9677  8234   389     1     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9943   422   418  9327  8702  7098  7141 16912 18328  8671  7415\n","   8263  8234   389     1     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815   410 21249 10174  6824  8210  8006 16146 11056 11594 10137\n","  10556  9266  8711 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815   410 21249  9183  7249 16146 11056 11594 10137 10556  9266\n","   8711 25856     1     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815 37655  9622  8619 10401  9183  9328   216  9443 29490  9846\n","   9788  9341 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815 37655 10135  7066 39488  9122  9050  9668 16576  9277  9044\n","  26519 19658  9098  7652  7801 25856     1     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815 37655 10135  7066  7692 11848  9042  7019 20284  7254 26519\n","  19658  9098  7652  7801 25856     1     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9815 37655 18381  9063  7489 29615  9054 15730 29452 13474  7380\n","   9033 10300 23775 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 19319 48397  8711  6947 19858 27031  9122  8046 25856     1     3\n","      3     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 19319 46651 27481 48397  8711  6947 19858 27031  9122  8046 25856\n","      1     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 19319  8135  9749 10225  6866  9677  7182  8749  9589 20540  7801\n","  25856     1     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 17230 17429  9160  8098  7237  8135  9427 35813  9122  8046 25856\n","      1     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 47980 22227 26992  7058  7182  7307  8137  9376  8737  8236  7801\n","  25856     1     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 26629 23799   739  8308  7304 10174  8707 10247 16346  6889  9282\n","   8400  7601  9078  7801 25856     1     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 15983  7673 24648  6889 25880  8006 27659 15582 46439 35557  6889\n","  12252  7801 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 15983  7673 24648 15010 10926  6853 27511 27659 15582 46439 35557\n","   6889 12252  7801 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 15983  7692 12371  9564 16409  9016  7182  8139  9271  9052  9267\n","  27545  8711  7661 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 15983  7692 36684  7220  9244  6958  9539  7478  6872  8006  7303\n","   7359  9124  9024  7801  8084   376     1     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 15983  7692 26873  9050  7177  7182  8139  9271  9052  9267 27545\n","   8711  7661 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1  9278 20861  9193   739  7570 47804 22864 20861 32392 10070 10828\n","  25856  9105 12114  9094 12191 12700 31279  8702 38887 15148 35441  9328\n","   9109  7801 25856     1]\n"," [    1 10464 12079  9028  9926  9651  8006  8054 27820  9432 23100 21833\n","  14247 29462  7801 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 10464 12079 17577  8054 27820  9432 23100 21833 14247 29462  7801\n","  25856     1     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 10464 12079 42076  9340   406  8054 27820  9432 23100 21833 14247\n","  29462  7801 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 10464  9341   406 35628  9659  9701 11389 11676  7177   387  9265\n","   7380 11120  8711 10764 11389  9728 12245 22238  9341  8084     1     3\n","      3     3     3     3]\n"," [    1 10464 10143  9666   739  8244 35628  9659  9701 11389 11676  7177\n","    387  9265  7380 11120  8711 10764 11389  9728 12245 22238  9341  8084\n","      1     3     3     3]\n"," [    1 10464 18264 12079  6826  9016  7208 25772  8267 25012  9069  6872\n","   7098 25856     1     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 10464  7285 10056 25799  8185  7235 25856     1     3     3     3\n","      3     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3]\n"," [    1 10464  9136  7380  9071  7513  8711  7182  7285  9117  7703  7788\n","  11120  8705 14553 10667  8718  7055  7661 25856     1     3     3     3\n","      3     3     3     3]\n"," [    1 10464  9136  7380  9071  7513  8711  8210  8006  7182  7285  9117\n","   7703  7788 11120  8705 14553 10667  8718  7055  7661 25856     1     3\n","      3     3     3     3]], shape=(32, 28), dtype=int32)\n"]}],"source":["for batch in dataset:\n","    print(batch)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1694406009370,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"GV_3ao2Q1dZz","outputId":"ad26a964-1764-4bf7-f501-0ac6da78111c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'</s> 12시 땡!하루가 또 가네요.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(batch[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694406010293,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"hTtsYuAC1gdz","outputId":"9762562d-97b2-4341-ee3b-f0bea40b8721"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[    1  9349  7888   739  7318   376 25000  6824  9108  9028  7098 25856\n","     1     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3], shape=(28,), dtype=int32)\n"]}],"source":["print(batch[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1694406011407,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"oDMlb21z1q0M","outputId":"5761d30f-6e33-4113-8524-69119a43d9db"},"outputs":[{"name":"stdout","output_type":"stream","text":["[9349, 7888, 739, 7318, 376, 12557, 6824, 9108, 9028, 7098, 25856]\n"]}],"source":["print(tokenizer.encode(' 12시 땡! 하루가 또 가네요.'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHLHR6gw1tpb"},"outputs":[],"source":["adam = tf.keras.optimizers.Adam(learning_rate = 3e-5, epsilon = 1e-08)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1694406014286,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"MNHwJMVZ10Db","outputId":"e656f13d-85e5-4b19-9727-7c4ed2946ffc"},"outputs":[{"name":"stdout","output_type":"stream","text":["370\n"]}],"source":["steps = len(train_data) // batch_size + 1\n","print(steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":509,"referenced_widgets":["da17f0f4eb7649e7bec64f5109fb0851","4c0203f8e9a04bb5835be6e3bdae29a1","8a890da2600543f68f54efcc288544b0","ef8e438deaee44f8b4126832b9d15f64","77b4cbdb58104bb29c6aa60ddf403535","4d354c58d4734e0ca1d3cee74ff84208","dc5f281c476040d7b802392e82ee3d4b","4b59776a36d14484aba8ba8dfede50fc","892aae2cf4a346f783dd552f41bd114b","7e52f174766c4b43a37ee266ee7827d6","d78e18dc8a184c83881ebc358321b6a0"]},"executionInfo":{"elapsed":444,"status":"error","timestamp":1694406015552,"user":{"displayName":"황태언","userId":"02206114473988724459"},"user_tz":-540},"id":"tYsAvNbZ2DSD","outputId":"5c7f3aba-657e-410c-c77e-72c6e68281e1"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-51-32d20f966673>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch in tqdm.tqdm_notebook(dataset, total = steps):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da17f0f4eb7649e7bec64f5109fb0851","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/370 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-32d20f966673>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   3807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m             warn_string = (\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got [-1, 0]"]}],"source":["EPOCHS = 3\n","\n","for epoch in range(EPOCHS):\n","  epoch_loss = 0\n","\n","  for batch in tqdm.tqdm_notebook(dataset, total = steps):\n","      with tf.GradientTape() as tape:\n","          result = model(batch, labels = batch)\n","          loss = result[0]\n","          batch_loss = tf.reduce_mean(loss)\n","\n","      grads = tape.gradient(batch_loss, model.trainable_variables)\n","      adam.apply_gradients(zip(grads, model.trainable_variables))\n","      epoch_loss += batch_loss / steps\n","\n","  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, epoch_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KlltJmD2HRy"},"outputs":[],"source":["text = '오늘도 좋은 하루!'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqFmg_Vi20s_"},"outputs":[],"source":["sent = '' + text + ''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsh5zgkm21FT"},"outputs":[],"source":["input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent)\n","input_ids = tf.convert_to_tensor([input_ids])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TO3dE9E22rT"},"outputs":[],"source":["output = model.generate(input_ids, max_length=50, early_stopping=True, eos_token_id=tokenizer.eos_token_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPFRhvte26Xa"},"outputs":[],"source":["decoded_sentence = tokenizer.decode(output[0].numpy().tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32ZCwvtl29dl"},"outputs":[],"source":["decoded_sentence.split(' ')[1].replace('', '')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Bx2f-_G29yW"},"outputs":[],"source":["output = model.generate(input_ids, max_length=50, do_sample=True, top_k=10)\n","tokenizer.decode(output[0].numpy().tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJUsh-ZB2_S1"},"outputs":[],"source":["def return_answer_by_chatbot(user_text):\n","  sent = '' + user_text + ''\n","  input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent)\n","  input_ids = tf.convert_to_tensor([input_ids])\n","  output = model.generate(input_ids, max_length=50, do_sample=True, top_k=20)\n","  sentence = tokenizer.decode(output[0].numpy().tolist())\n","  chatbot_response = sentence.split(' ')[1].replace('', '')\n","  return chatbot_response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBUcglhF3B0Q"},"outputs":[],"source":["return_answer_by_chatbot('안녕! 반가워~')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyjAGHQHbvMy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMefIRBNn1MI/wPuB9Cnn2V"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4b59776a36d14484aba8ba8dfede50fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c0203f8e9a04bb5835be6e3bdae29a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d354c58d4734e0ca1d3cee74ff84208","placeholder":"​","style":"IPY_MODEL_dc5f281c476040d7b802392e82ee3d4b","value":"  0%"}},"4d354c58d4734e0ca1d3cee74ff84208":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77b4cbdb58104bb29c6aa60ddf403535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e52f174766c4b43a37ee266ee7827d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892aae2cf4a346f783dd552f41bd114b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a890da2600543f68f54efcc288544b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b59776a36d14484aba8ba8dfede50fc","max":370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_892aae2cf4a346f783dd552f41bd114b","value":0}},"d78e18dc8a184c83881ebc358321b6a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da17f0f4eb7649e7bec64f5109fb0851":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c0203f8e9a04bb5835be6e3bdae29a1","IPY_MODEL_8a890da2600543f68f54efcc288544b0","IPY_MODEL_ef8e438deaee44f8b4126832b9d15f64"],"layout":"IPY_MODEL_77b4cbdb58104bb29c6aa60ddf403535"}},"dc5f281c476040d7b802392e82ee3d4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef8e438deaee44f8b4126832b9d15f64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e52f174766c4b43a37ee266ee7827d6","placeholder":"​","style":"IPY_MODEL_d78e18dc8a184c83881ebc358321b6a0","value":" 0/370 [00:00&lt;?, ?it/s]"}}}}},"nbformat":4,"nbformat_minor":0}